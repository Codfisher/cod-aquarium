import { randomUUID } from 'node:crypto'
import { createReadStream, createWriteStream, existsSync, readFileSync } from 'node:fs'
import { readdir, readFile, rename, unlink, writeFile } from 'node:fs/promises'
import path from 'node:path'
import process, { nextTick } from 'node:process'
import readline from 'node:readline/promises'
import { GoogleGenAI } from '@google/genai'
import PQueue from 'p-queue'
import { chunk, filter, pipe, tap } from 'remeda'
import sharp from 'sharp'
import phash from 'sharp-phash'
import distance from 'sharp-phash/distance'

const __dirname = import.meta.dirname

const SOURCE_PATH = 'D:/Google é›²ç«¯ç¡¬ç¢Ÿ/å¾…è™•ç† meme'
const IMAGE_EXTS = new Set(['.jpg', '.jpeg', '.png', '.webp'])

const MEME_FILE_PATH = path.resolve(__dirname, '../../content/public/memes')

/** é™„åŠ è³‡æ–™ã€‚ç‰ˆæœ¬ç­‰ç­‰ */
const MEME_META_PATH = path.resolve(__dirname, '../../content/public/memes/a-memes-meta.json')
/** åœ–ç‰‡è³‡æ–™ */
const MEME_DATA_PATH = path.resolve(__dirname, '../../content/public/memes/a-memes-data.ndjson')
/** æ‰‹å‹•åŠ å…¥çš„è³‡æ–™ */
const MEME_META_EXTEND_PATH = path.resolve(__dirname, '../../content/public/memes/a-memes-data-extend.ndjson')

/** åœ–ç‰‡ç›¸ä¼¼åº¦é–¾å€¼ */
const IMG_SIMILARITY_THRESHOLD = 10

async function readExistingFilenames(ndjsonPath: string): Promise<Set<string>> {
  const names = new Set<string>()
  if (!existsSync(ndjsonPath))
    return names

  const stream = createReadStream(ndjsonPath, { encoding: 'utf8' })
  const rl = readline.createInterface({ input: stream, crlfDelay: Infinity })
  for await (const line of rl) {
    const string = line.trim()
    if (!string)
      continue

    try {
      const obj = JSON.parse(string)
      const name = typeof obj?.file === 'string' ? obj.file : undefined
      if (name)
        names.add(name)
    }
    catch { }
  }
  return names
}

/** å–å¾—æª”æ¡ˆ */
async function getFilePathList(baseDirectory: string, { recursive = false } = {}) {
  const files: string[] = []

  async function walk(dirPath: string) {
    const entries = await readdir(dirPath, { withFileTypes: true })
    for (const entry of entries) {
      const fullPath = path.join(dirPath, entry.name)
      if (entry.isDirectory()) {
        if (recursive) {
          await walk(fullPath)
        }
      }
      else if (IMAGE_EXTS.has(path.extname(entry.name).toLowerCase())) {
        files.push(fullPath)
      }
    }
  }

  await walk(baseDirectory)
  return files
}

/** å–å¾— meme æª”æ¡ˆ */
async function getMemePathList() {
  const existingNames = await readExistingFilenames(MEME_DATA_PATH)

  const memeList = pipe(
    await getFilePathList(MEME_FILE_PATH),
    filter((filePath) => !existingNames.has(path.basename(filePath))),
  )

  return memeList
}

/** æ›´æ–° JSON æª”æ¡ˆï¼Œç§»é™¤å·²åˆªé™¤çš„ meme */
async function updateJsonData(dataPath: string, removedPaths: string[]) {
  if (!removedPaths.length)
    return

  const removedNames = removedPaths.map((value) => path.basename(value))

  const data = await readFile(dataPath, 'utf8')
  if (!data)
    return

  const lines = pipe(
    data.split(/\r?\n/),
    filter((line) => !removedNames.some((name) => line.includes(name))),
  )

  await writeFile(dataPath, lines.join('\n'), 'utf8')
}
/** åˆªé™¤é‡è¤‡è¿·å›  */
async function dedupeMeme() {
  const memePathList = await getFilePathList(MEME_FILE_PATH)

  const hashList = await Promise.all(memePathList.map(async (filePath) => {
    const file = await readFile(filePath)
    const hash = await phash(file)
    return { filePath, hash }
  }))

  const keptMemeList: { filePath: string; hash: string }[] = []
  const removedMemeList: string[] = []

  for (const item of hashList) {
    const isDuplicate = keptMemeList.some(
      (k) => distance(k.hash, item.hash) <= IMG_SIMILARITY_THRESHOLD,
    )

    if (isDuplicate) {
      await unlink(item.filePath)
      removedMemeList.push(item.filePath)
      continue
    }

    // ç•™ç¬¬ä¸€å¼µ
    keptMemeList.push(item)
  }

  // æ›´æ–°è³‡æ–™
  await updateJsonData(MEME_DATA_PATH, removedMemeList)
  await updateJsonData(MEME_META_EXTEND_PATH, removedMemeList)

  console.log(`[dedupeMeme] å·²åˆªé™¤ ${removedMemeList.length} å¼µé‡è¤‡åœ–ç‰‡`)
}

/** å£“ç¸®ç¾æœ‰æª”æ¡ˆï¼Œæœƒå¯«å…¥ temp è³‡æ–™å¤¾ä¸­ */
async function minifyCurrentMeme() {
  const fileList = await getFilePathList(MEME_FILE_PATH)
  const queue = new PQueue({ concurrency: 10 })

  const tasks = fileList.map((filePath) => queue.add(async () => {
    const newFile = await sharp(filePath)
      .resize({ width: 700, height: 700, fit: 'inside', withoutEnlargement: true })
      .flatten({ background: '#fff' })
      .webp({ quality: 60, effort: 6, smartSubsample: true })
      .toBuffer()

    await writeFile(path.join(
      path.dirname(filePath),
      'temp',
      path.basename(filePath),
    ), newFile)
  }))
  await Promise.all(tasks)
}
// minifyCurrentMeme().catch((e) => {
//   console.error(e)
// })

/** å¾ä¸Šå‚³è³‡æ–™å¤¾å¼•å…¥ meme */
async function importSourceMeme() {
  const fileList = await pipe(
    await readdir(SOURCE_PATH, { withFileTypes: true }),
    filter((item) => item.isFile()),
    async (list) => {
      const tasks = list.map(async (entry) => {
        const srcPath = path.join(SOURCE_PATH, entry.name)
        const file = await readFile(srcPath)
        let hash = ''
        try {
          hash = await phash(file)
        }
        catch (error) {
          console.error(`ğŸš€ ~ file:`, entry.name)
          console.error(`ğŸš€ ~ error:`, error)
        }

        return {
          entry,
          file,
          srcPath,
          hash,
        }
      })

      const dataList = pipe(
        await Promise.all(tasks),
        filter(({ hash }) => hash !== ''),
      )

      return dataList.reduce((result, dataItem) => {
        const isDuplicate = result.some((resultItem) =>
          distance(resultItem.hash, dataItem.hash) <= IMG_SIMILARITY_THRESHOLD,
        )

        if (!isDuplicate) {
          result.push(dataItem)
        }
        else {
          const filename = path.basename(dataItem.srcPath)
          unlink(dataItem.srcPath)
            .then(() => {
              console.log('[importSourceMeme] åˆªé™¤ä¾†æºé‡è¤‡åœ–ç‰‡ï¼š', filename)
            })
            .catch((e) => {
              console.warn('[importSourceMeme] åˆªé™¤ä¾†æºé‡è¤‡åœ–ç‰‡å¤±æ•—ï¼š', filename, e)
            })
        }

        return result
      }, [] as typeof dataList)
    },
  )

  const hashList = await pipe(
    await getFilePathList(MEME_FILE_PATH),
    (memePathList) => Promise.all(memePathList.map(async (filePath) => {
      const file = await readFile(filePath)
      const hash = await phash(file)
      return { filePath, hash }
    })),
  )

  let count = 0
  for (const { entry, file, hash, srcPath } of fileList) {
    const ext = path.extname(entry.name).toLowerCase()

    // åˆªé™¤ä¸ç¬¦åˆæ ¼å¼çš„æª”æ¡ˆ
    if (!IMAGE_EXTS.has(ext)) {
      try {
        await unlink(srcPath)
      }
      catch (e) {
        console.warn('[importSourceMeme] åˆªé™¤åœ–ç‰‡å¤±æ•—ï¼š', srcPath, e)
      }
      continue
    }

    // åˆ¤æ–·æ˜¯å¦é‡è¤‡
    const isDuplicate = hashList.some((data) => distance(data.hash, hash) <= IMG_SIMILARITY_THRESHOLD)
    if (isDuplicate) {
      try {
        await unlink(srcPath)
        console.log('[importSourceMeme] åˆªé™¤é‡è¤‡åœ–ç‰‡ï¼š', path.basename(srcPath))
      }
      catch (e) {
        console.warn('[importSourceMeme] åˆªé™¤é‡è¤‡åœ–ç‰‡å¤±æ•—ï¼š', path.basename(srcPath), e)
      }
      continue
    }

    // è½‰ webpã€æœ€é•·é‚Š 700px
    const id = randomUUID()
    const dstPath = path.join(MEME_FILE_PATH, `meme-${id}.webp`)

    try {
      await sharp(file)
        .resize({ width: 700, height: 700, fit: 'inside', withoutEnlargement: true })
        .flatten({ background: '#fff' })
        .webp({ quality: 60, effort: 6, smartSubsample: true })
        .toFile(dstPath)

      count++

      // åˆªé™¤ä¾†æºæª”
      try {
        await unlink(srcPath)
      }
      catch (e) {
        console.warn('[importSourceMeme] åˆªé™¤ä¾†æºæª”å¤±æ•—ï¼š', srcPath, e)
      }
    }
    catch (e) {
      console.error('[importSourceMeme] è½‰æª”å¤±æ•—ï¼š', srcPath, e)
    }
  }

  console.log(`[importSourceMeme] å·²åŒ¯å…¥ ${count} å¼µåœ–ç‰‡`)
}

async function main() {
  // await dedupeMeme()
  await importSourceMeme()

  const queue = new PQueue({ concurrency: 5 })
  const ai = new GoogleGenAI({
    apiKey: process.env.GEMINI_API_KEY,
  })
  const ndjsonStream = createWriteStream(MEME_DATA_PATH, { flags: 'a', encoding: 'utf8' })

  const memeFilePathList = await getMemePathList()
  console.log(`[main] ${memeFilePathList.length} å€‹æª”æ¡ˆå¾…è™•ç†`)

  let count = 0
  const tasks = memeFilePathList.map(async (filePath) => queue.add(async () => {
    const base64ImageFile = await readFile(filePath, { encoding: 'base64' })

    const contents = [
      {
        inlineData: {
          mimeType: 'image/webp',
          data: base64ImageFile,
        },
      },
      {
        text: [
          'ä½¿ç”¨æ­£é«”ä¸­æ–‡æè¿°åœ–ç‰‡ï¼Œå¥å­è¶Šç²¾ç°¡è¶Šå¥½ï¼Œæè¿°äººç‰©ã€æ™¯è‰²ã€æƒ…ç·’ã€å‡ºè‡ªç”šéº¼ä½œå“ï¼Œä¸è¦ä»»ä½•æ ¼å¼ï¼Œå¿½ç•¥æµ®æ°´å°',
          'è‹¥æœ‰æ–‡å­—ï¼Œå‰‡èªªæ˜æœ‰ç”šéº¼æ–‡å­—ï¼Œå¦å‰‡å¿½ç•¥',
          'è‹¥ç‚ºè«§éŸ³é›™é—œï¼Œå‰‡èªªæ˜åŸå§‹æ–‡å¥ï¼Œå¦å‰‡å¿½ç•¥',
        ].join('ã€‚'),
      },
    ]

    const response = await ai.models.generateContent({
      // model: 'gemini-2.5-pro',
      model: 'gemini-2.5-flash',
      contents,
    })

    const result = pipe(
      {
        file: path.basename(filePath),
        describe: response.text,
        ocr: '',
        keyword: '',
      },
      (data) => JSON.stringify(data).replaceAll('\n', ''),
    )

    // console.log(result)
    count++
    console.log(`[main] ${count}/${memeFilePathList.length}`)

    ndjsonStream.write(`${result}\n`)
  }))
  await Promise.all(tasks)

  await new Promise<void>((resolve, reject) => {
    ndjsonStream.on('finish', resolve)
    ndjsonStream.on('error', reject)
    ndjsonStream.end()
  })

  await writeFile(
    MEME_META_PATH,
    JSON.stringify({
      updatedAt: Math.floor(Date.now() / 1000),
    }),
    'utf8',
  )
  console.log('[main] done')
}

main().catch((e) => {
  console.error(e)
})
