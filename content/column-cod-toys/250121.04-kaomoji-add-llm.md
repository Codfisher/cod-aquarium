---
title: CodToys - EP04：請支援近義詞搜尋
description: 忘記顏文字的 tag 怎麼辦？請支援近義詞搜尋 ლ(╹ε╹ლ)
tags: ['Electron', 'LLM']
image: https://codlin.me/cod-toys.webp
date: 20250122
---

# CodToys - EP04：請支援近義詞搜尋

![快樂堆積木的魚](/cod-toys.webp){.cover}

上一章我們可以很快速地選擇目標顏文字了。

但是日子久了，可能會忘記顏文字的 tag，導致一時不知道怎麼找到想要的顏文字。%(◜௰◝)%

<br>

路人：「自己新增的 tag 還能忘記喔？%(◉◞౪◟◉ )%」

鱈魚：「我就鱈魚腦，你有意見膩？%(;´༎ຶД༎ຶ`)%」

<br>

既然如此，那就就來支援近義詞搜尋吧，這樣即使忘記原本的 tag，也可以透過相近的字詞找到想要的顏文字了！%ヾ(◍'౪`◍)ﾉﾞ%

## 開發

本章節預計會建立以下內容：

- 在 Electron 中運行 LLM
- 讓 LLM 對每個顏文字的 tag 產生近義詞
- 根據近義詞搜尋並顯示結果

### 來運行 LLM 吧！

這裡依賴 [`node-llama-cpp`](https://github.com/withcatai/node-llama-cpp) 這個套件，藉由此套件我們可以很簡單的在 Node.js 中運行 LLM。

程式碼很單純，基本上就是微調官方範例而已。

```typescript
import path from 'node:path'
import { fileURLToPath } from 'node:url'
import chalk from 'chalk'
import { getLlama, LlamaChatSession, resolveModelFile } from 'node-llama-cpp'

const __dirname = path.dirname(fileURLToPath(import.meta.url))
const modelsDirectory = path.join(__dirname, '..', 'models')

const llama = await getLlama()

const qList = [
  '快樂的 10 個繁體中文、10 個英文近義詞，全部合併，逗號分隔，不要任何附加資訊，不要標題，不需解釋',
  '慶祝的 10 個繁體中文、10 個英文近義詞，全部合併，逗號分隔，不要任何附加資訊，不要標題，不需解釋',
  '發瘋的 10 個繁體中文、10 個英文近義詞，全部合併，逗號分隔，不要任何附加資訊，不要標題，不需解釋'
]

{
  console.log(chalk.yellow('gemma: '))

  const modelPath = await resolveModelFile(
    'hf_bartowski_gemma-2-2b-it-Q6_K_L.gguf',
    modelsDirectory
  )

  const model = await llama.loadModel({ modelPath })
  const context = await model.createContext()
  const session = new LlamaChatSession({
    contextSequence: context.getSequence()
  })
  console.log()

  for (const q of qList) {
    const a = await session.prompt(q)
    console.log(a)
  }

  await model.dispose()
}

{
  console.log(chalk.yellow('llama: '))

  const modelPath = await resolveModelFile(
    'hf_mradermacher_Llama-3.2-3B-Instruct.Q6_K.gguf',
    modelsDirectory
  )

  const model = await llama.loadModel({ modelPath })
  const context = await model.createContext()
  const session = new LlamaChatSession({
    contextSequence: context.getSequence()
  })
  console.log()

  for (const q of qList) {
    const a = await session.prompt(q)
    console.log(a)
  }

  await model.dispose()
}
```

## 總結 🐟

以上程式碼可以[在此取得](https://github.com/Codfisher/side-project-cod-toys/tree/feat/kaomoji-add-llm)
