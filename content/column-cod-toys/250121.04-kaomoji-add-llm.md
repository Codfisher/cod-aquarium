---
title: CodToys - EP04：請支援近義詞搜尋
description: 忘記顏文字的 tag 怎麼辦？請支援近義詞搜尋 ლ(╹ε╹ლ)
tags: ['Electron', 'LLM']
image: https://codlin.me/cod-toys.webp
date: 20250122
---

# CodToys - EP04：請支援近義詞搜尋

![快樂堆積木的魚](/cod-toys.webp){.cover}

上一章我們可以很快速地選擇目標顏文字了。

但是日子久了，可能會忘記顏文字的 tag，導致一時不知道怎麼找到想要的顏文字。%(◜௰◝)%

<br>

路人：「自己新增的 tag 還能忘記喔？%(◉◞౪◟◉ )%」

鱈魚：「我就鱈魚腦，你有意見膩？%(;´༎ຶД༎ຶ`)%」

<br>

既然如此，那就就來支援近義詞搜尋吧，這樣即使忘記原本的 tag，也可以透過相近的字詞找到想要的顏文字了！%ヾ(◍'౪`◍)ﾉﾞ%

## 開發

本章節預計會建立以下內容：

- 在 Electron 中運行 LLM
- 讓 LLM 對每個顏文字的 tag 產生近義詞
- 根據近義詞搜尋並顯示結果

### 來運行 LLM 吧！

這裡依賴 [`node-llama-cpp`](https://github.com/withcatai/node-llama-cpp) 這個套件，藉由此套件我們可以很簡單的在 Node.js 中運行 LLM。

這裡選用小型的模型，目前實際測試 `gemma-2-2b-it-Q6_K_L` 和 `Llama-3.2-3B-Instruct.Q6_K`。

程式碼很單純，基本上就是微調官方範例而已。

讓模型回答特定單字的中英文近義詞，並將結果顯示出來。

```typescript
import path from 'node:path'
import { fileURLToPath } from 'node:url'
import chalk from 'chalk'
import { getLlama, LlamaChatSession, resolveModelFile } from 'node-llama-cpp'

const __dirname = path.dirname(fileURLToPath(import.meta.url))
const modelsDirectory = path.join(__dirname, '..', 'models')

const llama = await getLlama()

const qList = [
  '快樂的 10 個繁體中文、10 個英文近義詞，全部合併，逗號分隔，不要任何附加資訊，不要標題，不需解釋',
  '慶祝的 10 個繁體中文、10 個英文近義詞，全部合併，逗號分隔，不要任何附加資訊，不要標題，不需解釋',
  '發瘋的 10 個繁體中文、10 個英文近義詞，全部合併，逗號分隔，不要任何附加資訊，不要標題，不需解釋'
]

{
  console.log(chalk.yellow('gemma: '))

  const modelPath = await resolveModelFile(
    'hf_bartowski_gemma-2-2b-it-Q6_K_L.gguf',
    modelsDirectory
  )

  const model = await llama.loadModel({ modelPath })
  const context = await model.createContext()
  const session = new LlamaChatSession({
    contextSequence: context.getSequence()
  })
  console.log()

  for (const q of qList) {
    const a = await session.prompt(q)
    console.log(a)
  }

  await model.dispose()
}

{
  console.log(chalk.yellow('llama: '))

  const modelPath = await resolveModelFile(
    'hf_mradermacher_Llama-3.2-3B-Instruct.Q6_K.gguf',
    modelsDirectory
  )

  const model = await llama.loadModel({ modelPath })
  const context = await model.createContext()
  const session = new LlamaChatSession({
    contextSequence: context.getSequence()
  })
  console.log()

  for (const q of qList) {
    const a = await session.prompt(q)
    console.log(a)
  }

  await model.dispose()
}
```

以下是運行結果。

gemma:

```text
幸福、欣喜、愉悅、歡樂、開心、滿足、喜悅、興奮、滿足、舒暢
joy, happiness, delight, exhilaration, contentment, pleasure, satisfaction, excitement, bliss, comfort

慶祝、歡慶、慶典、盛會、派對、聚會、節慶、紀念、典禮、嘉年華
celebration, festivities, party, gathering, jubilee, festival, commemoration, gala, ceremony, parade, anniversary

發瘋、瘋狂、失控、歇斯底里、狂躁、衝動、失序、失常、暴躁、躁狂
madness, frenzy, unhinged, manic, agitated, impulsive, chaotic, disordered, irritable, erratic
```

llama:

```text
快樂、愉悅、幸福、欣快、高興、快意、悅目、愉悅、快樂、快暢
慶祝、祝賀、紀念、紀念、祝福、慶典、節日、節慶、紀念、祝賀
發瘋、癲癇、瘋狂、亢進、狂躁、癡呆、癲癇、瘋狂、亢進、狂躁
```

可以看出 gemma 的回答品質比 llama 好很多，所以接下來讓我們使用 gemma 實現近義詞搜尋吧。

### 新增 LLM API

## 總結 🐟

以上程式碼可以[在此取得](https://github.com/Codfisher/side-project-cod-toys/tree/feat/kaomoji-add-llm)
